{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Untitled.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SQvaPWVUmSUs","colab_type":"code","colab":{}},"source":["import sys, os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5A2pDd6urk4e","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsZL0b-zpNCE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"272194b5-caf5-41f9-fdaa-6080c1144679","executionInfo":{"status":"ok","timestamp":1583327078600,"user_tz":-330,"elapsed":39731,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GY6OLobVmSVF","colab_type":"code","colab":{}},"source":["BASEPATH='/content/drive/My Drive/face_and_emotion_detection-master'\n","MODELPATH = './models/model2.h5'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZ74CCF-mSVW","colab_type":"code","colab":{}},"source":["num_features = 64\n","num_labels = 7\n","batch_size = 64\n","epochs = 100\n","width, height = 48, 48"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QCFEp81cokGC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9f03343c-099b-47b9-b685-fd7bdcbe6349","executionInfo":{"status":"ok","timestamp":1583327663884,"user_tz":-330,"elapsed":1037,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["cd /content/drive/My Drive/face_and_emotion_detection-master"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/face_and_emotion_detection-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6OAI2woYmSVm","colab_type":"code","colab":{}},"source":["data = pd.read_csv('./fer2013.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubkpa6qQmSV1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"55f01c28-3d7a-4274-d8e5-8a0f10eb80c4","executionInfo":{"status":"ok","timestamp":1583327688029,"user_tz":-330,"elapsed":907,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["data.tail()"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>emotion</th>\n","      <th>pixels</th>\n","      <th>Usage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>35882</th>\n","      <td>6</td>\n","      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n","      <td>PrivateTest</td>\n","    </tr>\n","    <tr>\n","      <th>35883</th>\n","      <td>3</td>\n","      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n","      <td>PrivateTest</td>\n","    </tr>\n","    <tr>\n","      <th>35884</th>\n","      <td>0</td>\n","      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n","      <td>PrivateTest</td>\n","    </tr>\n","    <tr>\n","      <th>35885</th>\n","      <td>3</td>\n","      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n","      <td>PrivateTest</td>\n","    </tr>\n","    <tr>\n","      <th>35886</th>\n","      <td>2</td>\n","      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n","      <td>PrivateTest</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       emotion                                             pixels        Usage\n","35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n","35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n","35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n","35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n","35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"3ThmK5NwmSWJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"4fb4e7be-1d7c-4cef-d015-2e6e2edcc5c7","executionInfo":{"status":"ok","timestamp":1583327718936,"user_tz":-330,"elapsed":21796,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["pixels = data['pixels'].tolist() # 1\n","\n","faces = []\n","for pixel_sequence in pixels:\n","    face = [int(pixel) for pixel in pixel_sequence.split(' ')] # 2\n","    face = np.asarray(face).reshape(width, height) # 3\n","    \n","    # There is an issue for normalizing images. Just comment out 4 and 5 lines until when I found the solution.\n","    # face = face / 255.0 # 4\n","    # face = cv2.resize(face.astype('uint8'), (width, height)) # 5\n","    faces.append(face.astype('float32'))\n","\n","faces = np.asarray(faces)\n","faces = np.expand_dims(faces, -1) # 6\n","\n","emotions = pd.get_dummies(data['emotion']).as_matrix() # 7"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"A8z43uFfmSWb","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rn38GOf_mSWk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":91},"outputId":"c212c6c3-9060-4a39-d3ea-7396699ef2c8","executionInfo":{"status":"ok","timestamp":1583327738999,"user_tz":-330,"elapsed":1439,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["model = Sequential()\n","\n","model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n","model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(2*2*2*num_features, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(2*2*num_features, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(2*num_features, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_labels, activation='softmax'))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m9MNMRpYmSWu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5a433cf8-4d43-40f7-fdb7-509a861bea2b","executionInfo":{"status":"ok","timestamp":1583327748323,"user_tz":-330,"elapsed":1041,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["model.summary()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 46, 46, 64)        640       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 46, 46, 64)        36928     \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 46, 46, 64)        256       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 23, 23, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 23, 23, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 23, 23, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 23, 23, 128)       512       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 23, 23, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 11, 11, 256)       295168    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 11, 11, 256)       590080    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 5, 5, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 5, 5, 512)         2048      \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 5, 5, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               1049088   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 7)                 903       \n","=================================================================\n","Total params: 5,905,863\n","Trainable params: 5,902,151\n","Non-trainable params: 3,712\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nEZmGHatmSW5","colab_type":"code","colab":{}},"source":["model.compile(loss=categorical_crossentropy,\n","              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oa-uDCBkmSXH","colab_type":"code","colab":{}},"source":["lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VUCp_qImSXP","colab_type":"code","colab":{}},"source":["mkdir -p logs/fit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qxf8bZrDmSXY","colab_type":"code","colab":{}},"source":["tensorboard = TensorBoard(log_dir='./logs')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7Nz-mrlmSXi","colab_type":"code","colab":{}},"source":["early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wixhk4QLmSXs","colab_type":"code","colab":{}},"source":["checkpointer = ModelCheckpoint(MODELPATH, monitor='val_loss', verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"UcSltj4WmSX5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7a8f1d60-cfdf-4519-f7d8-e0a90520ff8e","executionInfo":{"status":"ok","timestamp":1583329121182,"user_tz":-330,"elapsed":1322360,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["model.fit(np.array(X_train), np.array(y_train),\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(np.array(X_test), np.array(y_test)),\n","          shuffle=True,\n","          callbacks=[lr_reducer, tensorboard, early_stopper, checkpointer])"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Train on 29068 samples, validate on 3589 samples\n","Epoch 1/100\n","   64/29068 [..............................] - ETA: 58:38 - loss: 7.2926 - acc: 0.0938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.200337). Check your callbacks.\n","29056/29068 [============================>.] - ETA: 0s - loss: 2.0441 - acc: 0.2068\n","Epoch 00001: val_loss improved from inf to 1.83997, saving model to ./models/model.h5\n","29068/29068 [==============================] - 48s 2ms/sample - loss: 2.0440 - acc: 0.2069 - val_loss: 1.8400 - val_acc: 0.2455\n","Epoch 2/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.8435 - acc: 0.2412\n","Epoch 00002: val_loss improved from 1.83997 to 1.83804, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.8435 - acc: 0.2412 - val_loss: 1.8380 - val_acc: 0.2455\n","Epoch 3/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.8215 - acc: 0.2493\n","Epoch 00003: val_loss did not improve from 1.83804\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.8215 - acc: 0.2493 - val_loss: 1.8991 - val_acc: 0.2455\n","Epoch 4/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.7680 - acc: 0.2776\n","Epoch 00004: val_loss improved from 1.83804 to 1.79695, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.7679 - acc: 0.2777 - val_loss: 1.7969 - val_acc: 0.2630\n","Epoch 5/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.6666 - acc: 0.3296\n","Epoch 00005: val_loss improved from 1.79695 to 1.58101, saving model to ./models/model.h5\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 1.6665 - acc: 0.3297 - val_loss: 1.5810 - val_acc: 0.3717\n","Epoch 6/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.5677 - acc: 0.3878\n","Epoch 00006: val_loss improved from 1.58101 to 1.50812, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.5676 - acc: 0.3878 - val_loss: 1.5081 - val_acc: 0.3970\n","Epoch 7/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.4907 - acc: 0.4157\n","Epoch 00007: val_loss improved from 1.50812 to 1.41337, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.4905 - acc: 0.4158 - val_loss: 1.4134 - val_acc: 0.4542\n","Epoch 8/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.4434 - acc: 0.4401\n","Epoch 00008: val_loss improved from 1.41337 to 1.38301, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.4433 - acc: 0.4401 - val_loss: 1.3830 - val_acc: 0.4742\n","Epoch 9/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.3985 - acc: 0.4588\n","Epoch 00009: val_loss did not improve from 1.38301\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.3987 - acc: 0.4588 - val_loss: 1.6625 - val_acc: 0.3667\n","Epoch 10/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.3683 - acc: 0.4750\n","Epoch 00010: val_loss improved from 1.38301 to 1.31645, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.3683 - acc: 0.4750 - val_loss: 1.3164 - val_acc: 0.4882\n","Epoch 11/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.3306 - acc: 0.4955\n","Epoch 00011: val_loss improved from 1.31645 to 1.29878, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.3308 - acc: 0.4955 - val_loss: 1.2988 - val_acc: 0.5079\n","Epoch 12/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.3017 - acc: 0.5073\n","Epoch 00012: val_loss did not improve from 1.29878\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.3019 - acc: 0.5072 - val_loss: 1.4577 - val_acc: 0.4269\n","Epoch 13/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.2749 - acc: 0.5209\n","Epoch 00013: val_loss improved from 1.29878 to 1.26665, saving model to ./models/model.h5\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 1.2749 - acc: 0.5209 - val_loss: 1.2666 - val_acc: 0.5124\n","Epoch 14/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.2514 - acc: 0.5330\n","Epoch 00014: val_loss improved from 1.26665 to 1.23009, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.2515 - acc: 0.5329 - val_loss: 1.2301 - val_acc: 0.5208\n","Epoch 15/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.2227 - acc: 0.5401\n","Epoch 00015: val_loss did not improve from 1.23009\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.2230 - acc: 0.5401 - val_loss: 1.2990 - val_acc: 0.5118\n","Epoch 16/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.2069 - acc: 0.5548\n","Epoch 00016: val_loss improved from 1.23009 to 1.13441, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.2069 - acc: 0.5547 - val_loss: 1.1344 - val_acc: 0.5779\n","Epoch 17/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.1789 - acc: 0.5622\n","Epoch 00017: val_loss did not improve from 1.13441\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 1.1788 - acc: 0.5623 - val_loss: 1.1864 - val_acc: 0.5464\n","Epoch 18/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.1571 - acc: 0.5724\n","Epoch 00018: val_loss did not improve from 1.13441\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 1.1572 - acc: 0.5724 - val_loss: 1.1545 - val_acc: 0.5681\n","Epoch 19/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.1351 - acc: 0.5845\n","Epoch 00019: val_loss improved from 1.13441 to 1.12283, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.1350 - acc: 0.5845 - val_loss: 1.1228 - val_acc: 0.5754\n","Epoch 20/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.1060 - acc: 0.5961\n","Epoch 00020: val_loss improved from 1.12283 to 1.10939, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.1062 - acc: 0.5961 - val_loss: 1.1094 - val_acc: 0.5874\n","Epoch 21/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.0905 - acc: 0.6019\n","Epoch 00021: val_loss improved from 1.10939 to 1.09671, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.0903 - acc: 0.6019 - val_loss: 1.0967 - val_acc: 0.5965\n","Epoch 22/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.0663 - acc: 0.6101\n","Epoch 00022: val_loss did not improve from 1.09671\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.0663 - acc: 0.6102 - val_loss: 1.1260 - val_acc: 0.5759\n","Epoch 23/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.0437 - acc: 0.6175\n","Epoch 00023: val_loss improved from 1.09671 to 1.06138, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 1.0438 - acc: 0.6175 - val_loss: 1.0614 - val_acc: 0.6088\n","Epoch 24/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.0220 - acc: 0.6251\n","Epoch 00024: val_loss did not improve from 1.06138\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.0221 - acc: 0.6251 - val_loss: 1.0758 - val_acc: 0.6049\n","Epoch 25/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 1.0101 - acc: 0.6333\n","Epoch 00025: val_loss did not improve from 1.06138\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 1.0101 - acc: 0.6333 - val_loss: 1.0986 - val_acc: 0.6046\n","Epoch 26/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.9857 - acc: 0.6430\n","Epoch 00026: val_loss improved from 1.06138 to 1.03640, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 0.9857 - acc: 0.6429 - val_loss: 1.0364 - val_acc: 0.6180\n","Epoch 27/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.9626 - acc: 0.6502\n","Epoch 00027: val_loss improved from 1.03640 to 1.02967, saving model to ./models/model.h5\n","29068/29068 [==============================] - 36s 1ms/sample - loss: 0.9626 - acc: 0.6503 - val_loss: 1.0297 - val_acc: 0.6236\n","Epoch 28/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.9462 - acc: 0.6587\n","Epoch 00028: val_loss did not improve from 1.02967\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 0.9460 - acc: 0.6587 - val_loss: 1.0480 - val_acc: 0.6258\n","Epoch 29/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.9314 - acc: 0.6635\n","Epoch 00029: val_loss improved from 1.02967 to 1.02218, saving model to ./models/model.h5\n","29068/29068 [==============================] - 37s 1ms/sample - loss: 0.9315 - acc: 0.6635 - val_loss: 1.0222 - val_acc: 0.6317\n","Epoch 30/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.9121 - acc: 0.6703\n","Epoch 00030: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 0.9120 - acc: 0.6704 - val_loss: 1.0737 - val_acc: 0.6155\n","Epoch 31/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.8965 - acc: 0.6739\n","Epoch 00031: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 0.8965 - acc: 0.6738 - val_loss: 1.0774 - val_acc: 0.6135\n","Epoch 32/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.8767 - acc: 0.6820\n","Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n","\n","Epoch 00032: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 0.8766 - acc: 0.6821 - val_loss: 1.0459 - val_acc: 0.6297\n","Epoch 33/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.8481 - acc: 0.6947\n","Epoch 00033: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 0.8482 - acc: 0.6947 - val_loss: 1.0452 - val_acc: 0.6194\n","Epoch 34/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.8260 - acc: 0.7014\n","Epoch 00034: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 0.8258 - acc: 0.7015 - val_loss: 1.0890 - val_acc: 0.6258\n","Epoch 35/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.8187 - acc: 0.7063\n","Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n","\n","Epoch 00035: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 0.8187 - acc: 0.7063 - val_loss: 1.0888 - val_acc: 0.6236\n","Epoch 36/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.7788 - acc: 0.7197\n","Epoch 00036: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 34s 1ms/sample - loss: 0.7788 - acc: 0.7197 - val_loss: 1.0498 - val_acc: 0.6428\n","Epoch 37/100\n","29056/29068 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.7262\n","Epoch 00037: val_loss did not improve from 1.02218\n","29068/29068 [==============================] - 35s 1ms/sample - loss: 0.7703 - acc: 0.7261 - val_loss: 1.0617 - val_acc: 0.6436\n","Epoch 00037: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f557d63df60>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"utNyf74KmSYF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9b2c4cdb-2f8c-4e26-e467-bab280fd120e","executionInfo":{"status":"ok","timestamp":1583329183683,"user_tz":-330,"elapsed":2228,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["scores = model.evaluate(np.array(X_test), np.array(y_test), batch_size=batch_size)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["3589/3589 [==============================] - 1s 369us/sample - loss: 1.0617 - acc: 0.6436\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zm5OKy_Hxixu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"13e92004-a829-4e2a-9c9f-b70b6900fc2f","executionInfo":{"status":"ok","timestamp":1583329207247,"user_tz":-330,"elapsed":1045,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["print(\"Loss: \" + str(scores[0]))\n","print(\"Accuracy: \" + str(scores[1]))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Loss: 1.0617364332117254\n","Accuracy: 0.6436333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DBWtxdCnxqGI","colab_type":"code","colab":{}},"source":["model.save(MODELPATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XGzjjV8y_M1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"a31b417b-34dc-41cf-a5f8-4153a3e38ef9","executionInfo":{"status":"ok","timestamp":1583329645556,"user_tz":-330,"elapsed":8527,"user":{"displayName":"NAMALA RAGHU VAMSHI 16BCE1260","photoUrl":"","userId":"13552294847503943164"}}},"source":["model_info=load_model('./models/model.h5')"],"execution_count":43,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]}]}